import whisper
from opencc import OpenCC
import sounddevice as sd
import numpy as np
import threading
import queue

# åˆ›å»ºéŸ³é¢‘æ•°æ®é˜Ÿåˆ—
audio_queue = queue.Queue()
# æ·»åŠ åœæ­¢æ ‡å¿—
stop_flag = threading.Event()

def audio_callback(indata, frames, time, status):
    """éŸ³é¢‘å›è°ƒå‡½æ•°ï¼Œå®æ—¶æ¥æ”¶éŸ³é¢‘æ•°æ®"""
    if not stop_flag.is_set():
        audio_queue.put(indata.copy())

def realtime_transcribe(model_size="medium"):
    """
    å®æ—¶å½•éŸ³å’Œè½¬å½•åŒæ—¶è¿›è¡Œ
    """
    # åŠ è½½æ¨¡å‹
    model = whisper.load_model(model_size).to("cuda")
    cc = OpenCC('t2s')
    # éŸ³é¢‘å‚æ•°
    fs = 16000  # é‡‡æ ·ç‡
    chunk_duration = 3  # æ¯3ç§’å¤„ç†ä¸€æ¬¡
    
    print("ğŸ¤ å¼€å§‹å®æ—¶å½•éŸ³å’Œè½¬å½•...")
    print("æŒ‰å›è½¦é”®åœæ­¢")
    print("-" * 40)
    
    # å¼€å§‹å½•éŸ³æµ
    stream = sd.InputStream(
        samplerate=fs,
        channels=1,
        callback=audio_callback,
        blocksize=int(fs * 0.5)  # 0.5ç§’çš„å—
    )
    stream.start()
    
    # éŸ³é¢‘ç¼“å†²åŒº
    audio_buffer = []
    total_duration = 0
    
    try:
        while not stop_flag.is_set():  # æ£€æŸ¥åœæ­¢æ ‡å¿—
            # è·å–éŸ³é¢‘æ•°æ®ï¼ˆéé˜»å¡ï¼‰
            try:
                audio_data = audio_queue.get(timeout=0.1)
                audio_buffer.append(audio_data)
                total_duration += len(audio_data) / fs
                
                # æ¯ chunk_duration ç§’å¤„ç†ä¸€æ¬¡
                if total_duration >= chunk_duration:
                    if audio_buffer:
                        # åˆå¹¶éŸ³é¢‘æ•°æ®
                        combined_audio = np.concatenate(audio_buffer, axis=0)
                        audio_float = combined_audio.flatten().astype(np.float32)
                        
                        # å®æ—¶è½¬å½•
                        result = model.transcribe(audio_float, language="zh")
                        text = cc.convert(result["text"])
                        
                        if text.strip():  # åªæ˜¾ç¤ºæœ‰å†…å®¹çš„è½¬å½•ç»“æœ
                            print(f"å®æ—¶è½¬å½•: {text}")
                            
                        # å†™å…¥æ–‡ä»¶
                        with open("a.txt", 'a', encoding='utf-8') as f:
                            f.write(text + "\n")
                        
                        # é‡ç½®ç¼“å†²åŒºå’Œè®¡æ—¶
                        audio_buffer = []
                        total_duration = 0
                        
            except queue.Empty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­å¾ªç¯
                continue
                
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        stream.stop()
        stream.close()
        print("\nå½•éŸ³å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åœ¨åå°å¯åŠ¨å®æ—¶è½¬å½•
    transcribe_thread = threading.Thread(target=realtime_transcribe, args=("medium",))
    transcribe_thread.start()
    
    # ä¸»çº¿ç¨‹ç­‰å¾…å›è½¦é”®
    input()  # ç­‰å¾…å›è½¦é”®
    
    # è®¾ç½®åœæ­¢æ ‡å¿—
    stop_flag.set()
    print("æ­£åœ¨åœæ­¢ç¨‹åº...")
    
    # ç­‰å¾…è½¬å½•çº¿ç¨‹ç»“æŸ
    transcribe_thread.join(timeout=2)
    print("ç¨‹åºå·²å®Œå…¨åœæ­¢")